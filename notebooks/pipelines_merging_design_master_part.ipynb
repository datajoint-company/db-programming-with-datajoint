{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint pipeline design - on \"merging\" of pipelines\n",
    "\n",
    "For DataJoint users working with existing pipelines or designing new ones, a common design question is on the topic of joining or merging different \"branches\" of the pipeline at one common node/table. \n",
    "\n",
    "To elaborate a bit more on this topic, let's say that in your workflow, there may be multiple sources of data that may need to go through different processing/analysis routines. But these different routines ultimately arrive at a point where the data format will be identical and can be further processed downstream in the same manner. \n",
    "\n",
    "In this notebook, we will go through one approach to address this design question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's consider one example scenario\n",
    "\n",
    "To be more concrete, let me start with an example. Let's say that we are interested in tracking the position of an animal during a freely behaving experiment. Ultimately, we want the `(x, y)` coordinates of the animal over time. In this example, for one experimental session, we are tracking the animal's position using either one of the two methods below:\n",
    "1. Placing a marker on the body of the animal and track this marker with a set of cameras\n",
    "2. Using computer vision approach to analyse the position of the animal from the video recording of a camera\n",
    "\n",
    "With each of the two tracking methods above, the processing and analysis will be different, and being DataJoint users, we'll design a set of tables to define the processing/analysis routine for each method.\n",
    "\n",
    "So there will likely be two pipeline branches going in parallel, but will need to be merged together at the point where the extraction of `(x, y)` coordinates over time is completed. As there will be set of analyses downstream to be done on top of the extracted animal position, regardless of which method the tracking of a particular exprimental session comes about. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pipeline for this scenario\n",
    "\n",
    "Let's put together an example DataJoint pipeline describing this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import uuid\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = dj.Schema('ttngu207_pipeline_merging_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class Session(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    animal_name: varchar(16)\n",
    "    session_number: int\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class MethodOneTrackingRaw(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Session\n",
    "    ---\n",
    "    tracking_data: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "@schema\n",
    "class MethodOneProcessing(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MethodOneTrackingRaw\n",
    "    ---\n",
    "    tracking_data: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "@schema\n",
    "class MethodOneTracking(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MethodOneProcessing\n",
    "    ---\n",
    "    x: longblob\n",
    "    y: longblob\n",
    "    t: longblob\n",
    "    \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class MethodTwoTrackingRaw(dj.Imported):\n",
    "    definition = \"\"\"\n",
    "    -> Session\n",
    "    ---\n",
    "    tracking_data: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "@schema\n",
    "class MethodTwoProcessing(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MethodTwoTrackingRaw\n",
    "    ---\n",
    "    tracking_data: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "@schema\n",
    "class FilterParam(dj.Lookup):\n",
    "    definition = \"\"\"\n",
    "    param_id: int\n",
    "    ---\n",
    "    sigma: float\n",
    "    \"\"\"\n",
    "    \n",
    "    contents = [(0, 1), (1, 10)]\n",
    "\n",
    "    \n",
    "@schema\n",
    "class MethodTwoFiltering(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MethodTwoProcessing\n",
    "    -> FilterParam\n",
    "    ---\n",
    "    filtered_tracking_data: longblob\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "@schema\n",
    "class MethodTwoTracking(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MethodTwoFiltering\n",
    "    ---\n",
    "    x: longblob\n",
    "    y: longblob\n",
    "    t: longblob\n",
    "    \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to \"merge\" these two branches?\n",
    "\n",
    "The next step in our pipeline is to run a number of analysis routines on the animal position data, using the `x, y, t` arrays as inputs. And we don't particularly care if the animal position data from a session is from method one or two, as long as we can work with the `x`, `y` and `t` arrays. \n",
    "\n",
    "Here, I will proposal a tables merging design approach. I opt for the term \"merging\" here to describe this joining/merging design to avoid confusion with DataJoint's `join`.\n",
    "\n",
    "Consider the design below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class MergedTracking(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    merged_tracking: uuid\n",
    "    \"\"\"\n",
    "    \n",
    "    class MethodOneTracking(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> master\n",
    "        ---\n",
    "        -> MethodOneTracking\n",
    "        \"\"\"\n",
    "        \n",
    "    class MethodTwoTracking(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> master\n",
    "        ---\n",
    "        -> MethodTwoTracking\n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "@schema\n",
    "class Speed(dj.Computed):\n",
    "    definition = \"\"\"\n",
    "    -> MergedTracking\n",
    "    ---\n",
    "    speed: longblob\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the prototype above, the `MergedTracking` table is a `dj.Manual` table allowing for the merging of the two different branches of tracking data. \n",
    "The primary key is a single uuid-type attribute, with no non-primary attribute.\n",
    "The connection to the upstream tables to be merged is done via part-tables, with one-to-one relationship to the master.\n",
    "\n",
    "One uuid entry here should uniquely specify one \"tracking\" for this session, either method one ***or*** method two. \n",
    "The keyword being ***or***, thus, there must be only one part-table having an entry corresponding to one entry in the master table, and none from the other part-tables.\n",
    "\n",
    "This design will allow for merging of tables from different branches of the pipeline (or from different pipelines), and fairly easily extendable. For example, say in the future there will be another tracking method, `MethodThreeTracking`, this can be added to the `MergedTracking` by introducing another part-table.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the catch?\n",
    "\n",
    "There are a few caveats in this design, I'm listing below two major ones. However, I'd say these are more inconveniences rather than design flaws or drawbacks. \n",
    "\n",
    "1. `UUID`-type primary attribute. The fact that the `MergedTracking` has single attribute of type `uuid` causing somewhat of a \"disconnection\" between this merging table and the upstream. The connection to upstream is established by the non-primary foreign keys. Three points of inconveniences from this:\n",
    "    + To link to the upstream tables, we always have to do a `join (*)` with this table and its part-tables in queries\n",
    "    + Cannot use this as a `dj.Imported` or `dj.Computed` - DataJoint native `autopopulate` would not work\n",
    "    + `.insert()` is hard to use, as the `uuid` has to be generated somehow\n",
    "    \n",
    "2. From the database perspective, this table design does not guarantee mutual exclusivity of the member tables to be merged. This means just purely from the table definition, one can have an entry in `MergedTracking` with corresponding entries in both the `MethodOneTracking` and `MethodTwoTracking` part-tables, violating the \"***or***\" intention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Can we enhance the experience?\n",
    "\n",
    "To enhance the usage experience, we can overwrite the `.insert()` method to:\n",
    "1. auto-generate the ***uuid*** \n",
    "2. insert also to the part-table\n",
    "3. ensure mutual exclusivity of member tables to be merged\n",
    "\n",
    "We can also introduce a convenient property `.all_joined` to:\n",
    "1. return the left join of the master tables with all of its parts\n",
    "2. downstream queries only need to join with `MergedTracking().all_joined` to be able to reference to the upstream tables being merged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@schema\n",
    "class MergedTracking(dj.Manual):\n",
    "    definition = \"\"\"\n",
    "    merged_tracking: uuid\n",
    "    \"\"\"\n",
    "    \n",
    "    class MethodOneTracking(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> master\n",
    "        ---\n",
    "        -> MethodOneTracking\n",
    "        \"\"\"\n",
    "        \n",
    "    class MethodTwoTracking(dj.Part):\n",
    "        definition = \"\"\"\n",
    "        -> master\n",
    "        ---\n",
    "        -> MethodTwoTracking\n",
    "        \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def all_joined(self):\n",
    "        parts = self.parts(as_objects=True)\n",
    "        primary_attrs = list(dict.fromkeys(itertools.chain.from_iterable([p.heading.names for p in parts])))\n",
    "        \n",
    "        query = dj.U(*primary_attrs) * parts[0].proj(..., **{a: 'NULL' for a in primary_attrs if a not in parts[0].heading.names})\n",
    "        for part in parts[1:]:\n",
    "            query += dj.U(*primary_attrs) * part.proj(..., **{a: 'NULL' for a in primary_attrs if a not in part.heading.names})\n",
    "\n",
    "        return query\n",
    "    \n",
    "    @classmethod\n",
    "    def insert(cls, rows, **kwargs):\n",
    "        \"\"\"\n",
    "        :param rows: An iterable where an element is a dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            for r in iter(rows):\n",
    "                assert isinstance(r, dict), 'Input \"rows\" must be a list of dictionaries'\n",
    "        except TypeError:\n",
    "                raise TypeError('Input \"rows\" must be a list of dictionaries')\n",
    "        \n",
    "        parts = cls.parts(as_objects=True)\n",
    "        master_entries = []\n",
    "        parts_entries = {p: [] for p in parts}\n",
    "        for row in rows:\n",
    "            key = {}\n",
    "            for part in parts:\n",
    "                parent = part.parents(as_objects=True)[-1]\n",
    "                if parent & row:\n",
    "                    if not key:\n",
    "                        key = (parent & row).fetch1('KEY')\n",
    "                        master_key = {cls.primary_key[0]: dj.hash.key_hash(key)}\n",
    "                        parts_entries[part].append({**master_key, **key})\n",
    "                        master_entries.append(master_key)\n",
    "                    else:\n",
    "                        raise ValueError(f'Mutual Exclusivity Error! Entry exists in more than one parent table - Entry: {row}')\n",
    "            \n",
    "            if not key:\n",
    "                raise ValueError(f'Non-existing entry in any of the parent tables - Entry: {row}')\n",
    "        \n",
    "        with cls.connection.transaction:\n",
    "            super().insert(cls(), master_entries, **kwargs)\n",
    "            for part, part_entries in parts_entries.items():\n",
    "                part.insert(part_entries, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's populate these tables with some mock data\n",
    "\n",
    "Let's create 4 sessions with mock data.\n",
    "\n",
    "Sessions 1 and 2 will be using method one, and session 3 and 4 will be using method two for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session.insert([('subject1', 1), ('subject1', 2), ('subject1', 3), ('subject1', 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodOneTrackingRaw.insert([('subject1', 1, np.random.randn(10)), ('subject1', 2, np.random.randn(10))], allow_direct_insert=True)\n",
    "MethodOneProcessing.insert([('subject1', 1, np.random.randn(10)), ('subject1', 2, np.random.randn(10))], allow_direct_insert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodTwoTrackingRaw.insert([('subject1', 3, np.random.randn(10)), ('subject1', 4, np.random.randn(10))], allow_direct_insert=True)\n",
    "MethodTwoProcessing.insert([('subject1', 3, np.random.randn(10)), ('subject1', 4, np.random.randn(10))], allow_direct_insert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodTwoFiltering.insert([('subject1', 3, 0, np.random.randn(10)), \n",
    "                           ('subject1', 4, 0, np.random.randn(10))], allow_direct_insert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodOneTracking.insert([('subject1', 1, np.random.randn(10), np.random.randn(10), np.arange(10)), \n",
    "                          ('subject1', 2, np.random.randn(10), np.random.randn(10), np.arange(10))], allow_direct_insert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodTwoTracking.insert([('subject1', 3, 0, np.random.randn(10), np.random.randn(10), np.arange(10)), \n",
    "                           ('subject1', 4, 0, np.random.randn(10), np.random.randn(10), np.arange(10))], allow_direct_insert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodOneTracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodTwoTracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's generate the corresponding entries in the `MergedTracking` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_one_entries = MethodOneTracking.fetch('KEY')\n",
    "method_two_entries = MethodTwoTracking.fetch('KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking.insert(method_one_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking.insert(method_two_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the `.all_joined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking().all_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few more example queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MergedTracking().all_joined & 'animal_name = \"subject1\"' & 'session_number = 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodOneTrackingRaw & (MergedTracking().all_joined & 'animal_name = \"subject1\"' & 'session_number = 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MethodTwoTrackingRaw & (MergedTracking().all_joined & 'animal_name = \"subject1\"' & 'session_number = 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Speed & (MergedTracking().all_joined & 'animal_name = \"subject1\"' & 'session_number = 3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
